#!/usr/bin/env python
# -*- coding: utf-8 -*-
# imports for the application
import csv
import copy
import argparse
import itertools
from collections import Counter
from collections import deque

import cv2 as cv
import numpy as np
import mediapipe as mp

from utils import CvFpsCalc
from model import KeyPointClassifier


# Arduino control
import serial
import time

ser = serial.Serial('COM3', 9600)

gesture_counter = 0
gesture_type = ""


# gets arguments such as size for camera/ non keyboard inputs
def get_args():
    parser = argparse.ArgumentParser()

    parser.add_argument("--device", type=int, default=0)
    parser.add_argument("--width", help='cap width', type=int, default=960)
    parser.add_argument("--height", help='cap height', type=int, default=540)

    # mediapipe prediction variables
    parser.add_argument('--use_static_image_mode', action='store_true')
    parser.add_argument("--min_detection_confidence",
                        help='min_detection_confidence',
                        type=float,
                        default=0.7)
    parser.add_argument("--min_tracking_confidence",
                        help='min_tracking_confidence',
                        type=int,
                        default=0.5)

    args = parser.parse_args()

    return args


# main function of the program
def main():
    # Argument parsing #################################################################
    args = get_args()

    cap_device = args.device
    cap_width = args.width
    cap_height = args.height

    use_static_image_mode = args.use_static_image_mode
    min_detection_confidence = args.min_detection_confidence
    min_tracking_confidence = args.min_tracking_confidence

    use_brect = True

    # Camera preparation ###############################################################
    cap = cv.VideoCapture(cap_device)
    cap.set(cv.CAP_PROP_FRAME_WIDTH, cap_width)
    cap.set(cv.CAP_PROP_FRAME_HEIGHT, cap_height)

    # Model load #############################################################
    mp_hands = mp.solutions.hands
    hands = mp_hands.Hands(
        static_image_mode=use_static_image_mode,
        max_num_hands=2,
        min_detection_confidence=min_detection_confidence,
        min_tracking_confidence=min_tracking_confidence,
    )
    # keypoint classifier class initialised
    keypoint_classifier = KeyPointClassifier()

    # Read labels
    keypoint_classifier_labels = ["Neutral", "Stop", "Direction", "Thanks"]

    # FPS Measurement
    cvFpsCalc = CvFpsCalc(buffer_len=10)

    mode = 0

    while True:
        fps = cvFpsCalc.get()

        # Process Key (ESC: end) #################################################
        key = cv.waitKey(10)
        if key == 27:  # ESC
            break
        number, mode = select_mode(key, mode)

        # Camera capture #####################################################
        ret, image = cap.read()
        if not ret:
            break
        # image = cv.flip(image, 1)  # Mirror display
        debug_image = copy.deepcopy(image)

        # Detection implementation #############################################################
        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)

        image.flags.writeable = False
        results = hands.process(image)
        image.flags.writeable = True

        #  ####################################################################
        if results.multi_hand_landmarks is not None:
            for hand_landmarks, handedness in zip(results.multi_hand_landmarks,
                                                  results.multi_handedness):
                # Bounding box calculation
                brect = calc_bounding_rect(debug_image, hand_landmarks)
                # Landmark calculation
                landmark_list = calc_landmark_list(debug_image, hand_landmarks)

                # Conversion to relative coordinates / normalized coordinates
                pre_processed_landmark_list = pre_process_landmark(
                    landmark_list)
                # Write to the dataset file
                logging_csv(number, mode, pre_processed_landmark_list)


                # Hand sign classification
                hand_sign_id = keypoint_classifier(pre_processed_landmark_list)

                led_on_off(led(hand_sign_id, handedness))

                # Drawing part
                debug_image = draw_bounding_rect(use_brect, debug_image, brect)
                debug_image = draw_landmarks(debug_image, landmark_list)
                debug_image = draw_info_text(
                    debug_image,
                    brect,
                    handedness,
                    keypoint_classifier_labels[hand_sign_id],
                )

        debug_image = draw_info(debug_image, fps, mode, number)

        # Screen reflection #
        cv.imshow('Hand Gesture Recognition', debug_image)

    # safely shut down camera and camera window
    cap.release()
    cv.destroyAllWindows()


# function to select program mode such as normal,logging key point and gesture id when logging
def select_mode(key, mode):
    number = -1
    if 48 <= key <= 57:  # 0 ~ 9
        number = key - 48
    if key == 110:  # n
        mode = 0
    if key == 107:  # k
        mode = 1
    return number, mode


# create a bounding box around the hand
def calc_bounding_rect(image, landmarks):
    # get image or frame height and width by the shape of the image.
    image_width, image_height = image.shape[1], image.shape[0]

    # uninitialised array in the form (x,y) of type int
    landmark_array = np.empty((0, 2), int)

    # loops the landmarks list
    for _, landmark in enumerate(landmarks.landmark):
        # gets the x and y points closest to edge based on position within image size
        landmark_x = min(int(landmark.x * image_width), image_width - 1)
        landmark_y = min(int(landmark.y * image_height), image_height - 1)

        # turns x and y into a coordinate point(x,y)
        landmark_point = [np.array((landmark_x, landmark_y))]
        # adds the xy point to an array
        landmark_array = np.append(landmark_array, landmark_point, axis=0)

    # uses openCV and the points calculated to get the coordinates of the bounding rectangle
    x, y, w, h = cv.boundingRect(landmark_array)

    # returns the co-ordinates for drawing later
    return [x, y, x + w, y + h]


# function for getting list of landmarks or all points of the han
def calc_landmark_list(image, landmarks):
    # gets the height and width of an image based on the shape
    image_width, image_height = image.shape[1], image.shape[0]

    # blank array for storing the points
    landmark_point = []

    # loops the landmark list from MediaPipe
    # finds the x co ordinate and y co ordinate based on its position and size of screen
    for _, landmark in enumerate(landmarks.landmark):
        landmark_x = min(int(landmark.x * image_width), image_width - 1)
        landmark_y = min(int(landmark.y * image_height), image_height - 1)
        # landmark_z = landmark.z

        # combines into co ordinate format and appends the co ordinate to the array
        landmark_point.append([landmark_x, landmark_y])

    return landmark_point


# function to change co ordinate points relative to a pivot point(wrist (0,0))
def pre_process_landmark(landmark_list):
    # copies the list from the previous calc_landmarks function
    temp_landmark_list = copy.deepcopy(landmark_list)

    # Convert to relative coordinates
    # base co ordinates are 0, 0
    base_x, base_y = 0, 0
    # loops list and highlights the index and points
    for index, landmark_point in enumerate(temp_landmark_list):
        # checks if first index which is the x point of wrist
        if index == 0:
            # sets the first two points or x and y of wrist to 0,0
            base_x, base_y = landmark_point[0], landmark_point[1]

        # creates new coordinates based on the amount the wrist x and y changed compared to 0,0
        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x
        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y

    # Convert to a one-dimensional list
    temp_landmark_list = list(
        itertools.chain.from_iterable(temp_landmark_list))

    # Normalization by returning the absolute maximum value of the list
    max_value = max(list(map(abs, temp_landmark_list)))

    # normalizes each value in the list by dividing by the maximum value in the list
    def normalize_(n):
        return n / max_value

    temp_landmark_list = list(map(normalize_, temp_landmark_list))

    # returns the normalized list with relative co ordinates
    return temp_landmark_list



# function for writing the landmarks points to the training CSV
def logging_csv(number, mode, landmark_list):
    # if in base mode dont use function
    if mode == 0:
        pass
    # if mode is 1 and there is a number to identify the gesture present also
    if mode == 1 and (0 <= number <= 9):
        # sets the CSV path
        csv_path = 'model/keypoint_classifier/keypoint.csv'
        # appends the values to the csv
        with open(csv_path, 'a', newline="") as f:
            writer = csv.writer(f)
            # indentifcation for the gesture followed by the list which contains relative normalised coordinates
            writer.writerow([number, *landmark_list])
    return


# function for drawing the landmarks on the frame
def draw_landmarks(image, landmark_point):
    # check to see if list exists
    if len(landmark_point) > 0:
        # uses opencv to draw lines between two points colour black
        # Thumb
        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),
                (255, 255, 255), 2)

        # Index finger
        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),
                (255, 255, 255), 2)

        # Middle finger
        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),
                (255, 255, 255), 2)

        # Ring finger
        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),
                (255, 255, 255), 2)

        # Little finger
        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),
                (255, 255, 255), 2)

        # Palm
        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),
                (255, 255, 255), 2)

    # Key Points
    # uses the list and list index to draw red circle on each landmark key point
    for index, landmark in enumerate(landmark_point):
        # wrist point
        if index == 0:
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 1:
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 2:
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 3:
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 4:
            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)
        if index == 5:
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 6:
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 7:
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 8:
            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)
        if index == 9:
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 10:
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 11:
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 12:
            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)
        if index == 13:
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 14:
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 15:
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 16:
            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)
        if index == 17:
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 18:
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 19:
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 20:
            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)

    # returns the image with black lines between the key points and red circles on the key points
    return image


# takes the image with lines and circles and the brect calculated in the calc_boudning_rect function to draw
# rectangle around the furthest spaced apart hand points
def draw_bounding_rect(use_brect, image, brect):
    if use_brect:
        # Outer rectangle
        cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),
                     (0, 0, 0), 1)

    # returns image with rect
    return image


# places information about the gesture on the screen
def draw_info_text(image, brect, handedness, hand_sign_text):

    # draws a smaller rectangle at the top of the previous rectangle to contain information about the gesture
    cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 22),
                 (0, 0, 0), -1)

    # handedness
    info_text = handedness.classification[0].label[0:]
    # adds the gesture name if it exists
    if hand_sign_text != "":
        info_text = info_text + ':' + hand_sign_text
    # places the text into the small rectangle created with Font, colour etc
    cv.putText(image, info_text, (brect[0] + 5, brect[1] - 4),
               cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv.LINE_AA)


    return image


# function to show the image, mode, fps, and number
def draw_info(image, fps, mode, number):
    cv.putText(image, "FPS:" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,
               1.0, (0, 0, 0), 4, cv.LINE_AA)
    cv.putText(image, "FPS:" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,
               1.0, (255, 255, 255), 2, cv.LINE_AA)

    mode_string = ['Logging Key Point', 'Logging Point History']
    if 1 <= mode <= 2:
        cv.putText(image, "MODE:" + mode_string[mode - 1], (10, 90),
                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,
                   cv.LINE_AA)
        if 0 <= number <= 9:
            cv.putText(image, "NUM:" + str(number), (10, 110),
                       cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,
                       cv.LINE_AA)
    return image


# function for ensuring the gesture recognised in recognised for a length of time and not just momentary
def led(hand_sign_id, handedness):
    # global variables as they need to be accessed outside the function
    global gesture_type
    global gesture_counter

    # if hand sign is stop
    if hand_sign_id == 1:
        # if it already is stop
        if (gesture_type == "Stop"):
            # increases counter
            gesture_counter += 1
        # if not stop
        else:
            # sets to stop
            gesture_type = "Stop"
            # adds to counter
            gesture_counter = 1

    # right and left counter
    elif hand_sign_id == 2:
        if (gesture_type == handedness.classification[0].label[0:]):
            gesture_counter += 1
        else:
            gesture_type = handedness.classification[0].label[0:]
            gesture_counter = 1

    # thanks counter
    elif hand_sign_id == 3:
        if (gesture_type == "Thanks"):
            gesture_counter += 1
        else:
            gesture_type = "Thanks"
            gesture_counter = 1

    # neutral counter
    else:
        if (gesture_type == "Neutral"):
            gesture_counter += 1
        else:
            gesture_type = "Neutral"
            gesture_counter = 1

    # if hand signal present for length of time returns the gesture otherwise none
    if gesture_counter > 10:
        return gesture_type
    else:
        return ""


# takes the gesture returned in the previous verification led function
def led_on_off(input):
    # checks input
    # if stop
    if input == "Stop":
        print("STOP")
        time.sleep(0.1)
        # writes through the serial s which has been configured to show red on the arduino
        ser.write(b'S')
    # if left
    elif input == "Left":
        print("LEFT")
        time.sleep(0.1)
        # serial write L which turns on left LED
        ser.write(b'L')
    # if right
    elif input == "Right":
        print("RIGHT")
        time.sleep(0.1)
        # serial write R which turns on right LED
        ser.write(b'R')
    # if neutral
    elif input == "Neutral":
        print("NEUTRAL")
        time.sleep(0.1)
        # writes N which turns off all LED
        ser.write(b'N')
    # if thanks
    elif input == "Thanks":
        print("THANKS")
        time.sleep(0.1)
        # writes T to serial port which turns on both L/R LEDs
        ser.write(b'T')


# run the program
if __name__ == '__main__':
    main()
